---
layout: about
title: about
permalink: /
subtitle: <a href='https://seas.harvard.edu/'>Harvard University - John A. Paulson School of Engineering and Applied Sciences</a>.

profile:
  align: right
  image: claudio2.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>150 Western Ave, Allston, MA 02134</p>

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hi! I am Claudio. Thanks for visiting my website and for your time. 

I am a mathematician working with AI and machine learning at [Harvard's School of Engineering and Applied Sciences](https://seas.harvard.edu/) under the mentorship of [Flavio Calmon](https://people.seas.harvard.edu/~flavio/). My research focuses on building the mathematical foundations of trustworthy AI, developing rigorous frameworks, algorithms, and theoretical guarantees for deploying AI systems safely and equitably. I harness tools from optimization, statistics, information theory, and signal processing to advance both theory and practice. I am currently most excited about:

**Inference-time alignment and post-training.** I develop principled methods for aligning AI systems at inference time, without additional training. This includes [introducing Soft-Best-of-n sampling](https://arxiv.org/pdf/2506.19248), [introducing Best-of-Poisson and establishing theoretical frameworks for reward hacking in inference-time methods](https://arxiv.org/pdf/2506.19248), and [devising provably robust watermarking schemes](https://arxiv.org/pdf/2506.06409) for LLM provenance and accountability.

**Fairness, accountability, and discretion in AI.** I work on rigorous fairness guarantees for generative systems, emphasizing intersectional equity. My research includes [developing methods for measuring representation across intersectional groups in retrieval](https://proceedings.neurips.cc/paper_files/paper/2024/file/d00fcdd0629dabdf515b1e6425a261bb-Paper-Conference.pdf) and [generative models](https://openaccess.thecvf.com/content/CVPR2025/papers/Jung_Multi-Group_Proportional_Representations_for_Text-to-Image_Models_CVPR_2025_paper.pdf), and [formalizing how values and principles are interpreted when safety rules conflict or are ambiguous](https://arxiv.org/pdf/2502.10441).

**Interpretability and sparse representations.** I develop techniques to elucidate the inner workings of large models, particularly through sparse autoencoders and parsimonious representations. My work includes [p-annelaing for training sparse autoencoders](https://proceedings.neurips.cc/paper_files/paper/2024/file/9736acf007760cc2b47948ae3cf06274-Paper-Conference.pdf) and [temporal sparse autoencoders that leverage the sequential nature of language for interpretability](https://openreview.net/pdf?id=hgPf1ki6dx). I focus on how sparsity can be used to extract interpretable features that capture semantic rather than merely syntactic information.

More broadly, my past work has focused on establishing rigorous algorithms with optimal sample complexity and fast convergence rates for fundamental machine learning problems, including [sparse regression](https://proceedings.neurips.cc/paper_files/paper/2021/file/16bda725ae44af3bb9316f416bd13b1b-Paper.pdf), [matrix completion](http://proceedings.mlr.press/v139/kummerle21a/kummerle21a.pdf), and [noise-blind problems](https://proceedings.mlr.press/v247/mayrink-verdun24a/mayrink-verdun24a.pdf). I have also developed [rigorous uncertainty quantification methods for high-dimensional problems](https://proceedings.neurips.cc/paper_files/paper/2024/file/dd65d612d2ddafd54ef5eceb92f1a754-Paper-Conference.pdf) and explored [connections between overparameterization and classical optimization](https://arxiv.org/pdf/2207.08437). I'm also passionate about applying these techniques to practical domains such as healthcare (particularly medical imaging) and education. Beyond technical research, I actively collaborate with lawyers and policymakers on AI governance, including [contributing to the G20 Summit policy discussions](https://www.t20brasil.org/media/documentos/arquivos/TF05_ST_05_AI_TECHNOLOGIES66cdc9e290631.pdf) to bridge the gap between technical innovation and responsible AI deployment.

I had the privilege of completing my Ph.D. in mathematics and electrical engineering (summa cum laude) under the guidance of [Felix Krahmer](https://www.professoren.tum.de/en/krahmer-felix/) within the [Optimization and Data Analysis group](https://www.math.cit.tum.de/en/math/research/groups/data-science/), while concurrently affiliated to the [Information Theory group](https://www.ce.cit.tum.de/en/lti/home/) under the leadership of [Holger Boche](https://www.professoren.tum.de/en/boche-holger/) at the [Technical University of Munich](www.tum.de).

<!-- Outside the university, you can find me traveling to some off-the-beaten-path places or reading about international politics.--> 

<!--Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.-->

<!--Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.-->
